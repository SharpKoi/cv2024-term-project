{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b926aa68-1a50-47ff-9492-72a2861dacf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as path_join\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as T\n",
    "import lightning as L\n",
    "\n",
    "from data import AidaDataset\n",
    "from transforms import FixedAspectResize, RandomSpots\n",
    "from tokenizers import LaTeXTokenizer\n",
    "from models import LaTeXOCREncoder, LaTeXOCRDecoder, LaTeXOCRModel, LitLaTeXOCRModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e0ecc8-449c-4eb5-9e74-08590ae2556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ocr_model(tokenizer: LaTeXTokenizer):\n",
    "    encoder_backbone = torchvision.models.efficientnet_v2_m().features[:-1]\n",
    "    encoder = LaTeXOCREncoder(\n",
    "        encoder_backbone, \n",
    "        d_backbone=512, \n",
    "        d_model=128\n",
    "    )\n",
    "\n",
    "    decoder = LaTeXOCRDecoder(\n",
    "        tokenizer.vocab_size, \n",
    "        d_model=128, \n",
    "        n_heads=4, \n",
    "        ff_dim=256, \n",
    "        n_layers=3, \n",
    "        dropout=0.1\n",
    "    )\n",
    "\n",
    "    return LaTeXOCRModel(encoder, decoder, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd8903b0-acb8-4cc5-ab63-de75641b9abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/cleaned_aida\"\n",
    "\n",
    "SEED = 101\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "INPUT_SIZE = 512\n",
    "BATCH_SIZE = 8\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33bef520-1362-4c4e-8459-fff876579d73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50bae4c357bf43aba15b98e548deee71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615fd0b8ee2941d789ca976c8e07e738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_transform = T.Compose([\n",
    "    RandomSpots(spots_range=(3, 7), w_range=(5, 10), h_range=(3, 5)),\n",
    "    T.ToImage(),\n",
    "    FixedAspectResize(512),\n",
    "])\n",
    "test_transform = T.Compose([\n",
    "    T.ToImage(),\n",
    "    FixedAspectResize(512),\n",
    "])\n",
    "train_set = AidaDataset(DATA_DIR, mode=\"train\", transform=train_transform)\n",
    "test_set = AidaDataset(DATA_DIR, mode=\"test\", transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2652b5ec-0a78-43ff-962a-b7c8c7a692ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "tokenizer = LaTeXTokenizer.load_from(path_join(DATA_DIR, \"vocab.json\"))\n",
    "model = build_ocr_model(tokenizer, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa96d1de-6877-4622-abe6-558f90ed66a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/311505018/Projects/cv2024-term-project/.venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'ignore_indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer()\n\u001b[0;32m----> 2\u001b[0m lit_model \u001b[38;5;241m=\u001b[39m \u001b[43mLitLaTeXOCRModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/cv2024-term-project/models.py:195\u001b[0m, in \u001b[0;36mLitLaTeXOCRModel.__init__\u001b[0;34m(self, model, lr, weight_decay)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_decay \u001b[38;5;241m=\u001b[39m weight_decay\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcer_metric \u001b[38;5;241m=\u001b[39m \u001b[43mCharacterErrorRate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'ignore_indices'"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer()\n",
    "lit_model = LitLaTeXOCRModel(model, lr=LR, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612dc00-0768-49ff-8c8c-9bb286fe27ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
